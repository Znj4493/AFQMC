import json
import re
import random
import threading
import time
import argparse
import os
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI
from tqdm import tqdm

# ä¿®å¤ Windows ç»ˆç«¯ä¸­æ–‡ç¼–ç é—®é¢˜
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# ==================== å¹³å°é…ç½® ====================
PLATFORMS = {
    "nvidia": {
        "type": "openai",  # ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
        "base_url": "https://integrate.api.nvidia.com/v1",
        "api_key": "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",
    },
    "zhipu": {
        "type": "zhipu",  # ä½¿ç”¨æ™ºè°±åŸç”Ÿ SDK
        "api_key": "5672204330d24299977d56cf8edb1f2f.mq8J3aAgMRswVzXu",
    },
    "zhipu_zai": {
        "type": "zai",  # ä½¿ç”¨ zai SDK (glm-4.6 ç­‰æ–°æ¨¡å‹)
        "api_key": "5672204330d24299977d56cf8edb1f2f.mq8J3aAgMRswVzXu",
    },
    "custom": {
        "type": "openai",  # ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
        "base_url": "http://106.53.8.125:21207/v1",
        "api_key": "sk-1180c2b72d4b17c9885ab6ec7df404a2",  # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™… API Key
    },
    # æ–°å¢å¹³å°åªéœ€åœ¨è¿™é‡Œæ·»åŠ 
}

# ==================== æ¨¡å‹é…ç½® ====================
MODEL_CONFIGS = {
    # --- NVIDIA å¹³å° ---
    "qwen3": {
        "platform": "nvidia",
        "model_id": "qwen/qwen3-next-80b-a3b-instruct",
        "max_tokens": 512,
        "extra_body": None,
        "max_workers": 5,
    },
    "glm4.7": {
        "platform": "nvidia",
        "model_id": "z-ai/glm4.7",
        "max_tokens": 512,
        "extra_body": {"chat_template_kwargs": {"enable_thinking": True}},
        "max_workers": 1,
    },
    "glm4.7-nothink": {
        "platform": "nvidia",
        "model_id": "z-ai/glm4.7",
        "max_tokens": 512,
        "extra_body": {"chat_template_kwargs": {"enable_thinking": False}},
        "max_workers": 1,
    },
    "deepseek-v3.2": {
        "platform": "nvidia",
        "model_id": "deepseek-ai/deepseek-v3.2",
        "max_tokens": 512,
        "extra_body": None,
        "max_workers": 5,
    },
    # --- æ™ºè°±å¹³å° ---
    "glm4.7-flash": {
        "platform": "zhipu",
        "model_id": "glm-4.7-flash",
        "max_tokens": 4096,
        "thinking": False,  # æ˜¾å¼ç¦ç”¨ thinking
        "max_workers": 1,
    },
    "glm4.7-flash-think": {
        "platform": "zhipu",
        "model_id": "glm-4.7-flash",
        "max_tokens": 65536,
        "thinking": True,
        "max_workers": 1,
    },
    "glm4.6": {
        "platform": "zhipu_zai",
        "model_id": "glm-4.6",
        "max_tokens": 4096,
        "thinking": False,
        "max_workers": 3,
    },
    "glm4.6-think": {
        "platform": "zhipu_zai",
        "model_id": "glm-4.6",
        "max_tokens": 65536,
        "thinking": True,
        "max_workers": 3,
    },
    # --- Custom å¹³å° ---
    "gpt5.2": {
        "platform": "custom",
        "model_id": "gpt-5.2",
        "max_tokens": 4096,
        "extra_body": None,
        "max_workers": 10,  
        "params": {  # è‡ªå®šä¹‰å‚æ•°
            "temperature": 0.1,
            "top_p": 0.95,
            "reasoning_effort": "low",  
        },
    },
    # æ–°å¢æ¨¡å‹åªéœ€åœ¨è¿™é‡Œæ·»åŠ é…ç½®å³å¯
}

# ==================== å®¢æˆ·ç«¯ç®¡ç† ====================
_clients = {}

def get_client(platform_name):
    """è·å–æˆ–åˆ›å»ºå¹³å°å¯¹åº”çš„å®¢æˆ·ç«¯"""
    if platform_name in _clients:
        return _clients[platform_name]

    platform = PLATFORMS[platform_name]

    if platform["type"] == "openai":
        client = OpenAI(base_url=platform["base_url"], api_key=platform["api_key"])
    elif platform["type"] == "zhipu":
        from zhipuai import ZhipuAI
        client = ZhipuAI(api_key=platform["api_key"])
    elif platform["type"] == "zai":
        from zai import ZhipuAiClient
        client = ZhipuAiClient(api_key=platform["api_key"])
    else:
        raise ValueError(f"æœªçŸ¥å¹³å°ç±»å‹: {platform['type']}")

    _clients[platform_name] = client
    return client

# ==================== Prompt ====================
PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡è¯­ä¹‰ç›¸ä¼¼åº¦åˆ¤æ–­ä¸“å®¶ï¼Œä¸“æ³¨äºé‡‘èé¢†åŸŸé—®ç­”çš„è¯­ä¹‰ç†è§£ã€‚

ã€ä»»åŠ¡ã€‘åˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦è¡¨è¾¾ç›¸åŒæˆ–ç›¸è¿‘çš„æ„æ€ã€‚

ã€åˆ¤æ–­æ ‡å‡†ã€‘
- ç›¸ä¼¼(1)ï¼šä¸¤å¥è¯è¯¢é—®åŒä¸€ä¸ªé—®é¢˜ï¼Œæˆ–è¡¨è¾¾ç›¸åŒçš„æ„å›¾ï¼Œå³ä½¿ç”¨è¯ã€å¥å¼ä¸åŒä¹Ÿç®—ç›¸ä¼¼
- ä¸ç›¸ä¼¼(0)ï¼šè¯¢é—®ä¸åŒçš„é—®é¢˜ï¼Œæˆ–è¡¨è¾¾ä¸åŒ/ç›¸åçš„æ„å›¾

ã€ç¤ºä¾‹ã€‘
å¥å­1ï¼šèŠ±å‘—å¯ä»¥ç”¨äºè´­ä¹°é»„é‡‘å—
å¥å­2ï¼šåœ¨æ”¯ä»˜å®ä¹°é»„é‡‘æ”¯æŒèŠ±å‘—ä»˜æ¬¾å—
åˆ†æï¼šä¸¤å¥éƒ½åœ¨é—®èƒ½å¦ç”¨èŠ±å‘—ä¹°é»„é‡‘ï¼Œæ„å›¾ç›¸åŒ
ç­”æ¡ˆï¼š1

å¥å­1ï¼šå¦‚ä½•åœ¨ä½¿ç”¨èŠ±å‘—è´­ç‰©åæ›´æ–°æ”¶è´§åœ°å€
å¥å­2ï¼šç§»é™¤èŠ±å‘—è´¦æˆ·ä¸­å·²ä¿å­˜çš„æ”¶è´§åœ°å€
åˆ†æï¼šä¸€ä¸ªé—®æ›´æ–°åœ°å€ï¼Œä¸€ä¸ªé—®åˆ é™¤åœ°å€ï¼Œæ„å›¾ä¸åŒ
ç­”æ¡ˆï¼š0

å¥å­1ï¼šå€Ÿå‘—ç¬¬äºŒæ¬¡å€Ÿæ¬¾çš„è¿˜æ¬¾æ—¥æœŸä¼šæ”¹å˜å—
å¥å­2ï¼šå€Ÿå‘—æ¯æœˆè¿˜æ¬¾æ—¥èƒ½æ”¹å—
åˆ†æï¼šéƒ½åœ¨é—®è¿˜æ¬¾æ—¥æœŸæ˜¯å¦å¯å˜ï¼Œæ„å›¾ç›¸åŒ
ç­”æ¡ˆï¼š1

å¥å­1ï¼šèŠ±å‘—è¿‡å»å¯ç”¨äºæ”¯ä»˜æ—¥å¸¸å¼€é”€è´¹ç”¨
å¥å­2ï¼šç”Ÿæ´»ç¼´è´¹åŠŸèƒ½ç›®å‰æ— æ³•é€šè¿‡èŠ±å‘—å®Œæˆ
åˆ†æï¼šä¸€ä¸ªè¯´å¯ä»¥ç”¨ï¼Œä¸€ä¸ªè¯´ä¸èƒ½ç”¨ï¼Œæ„å›¾ç›¸å
ç­”æ¡ˆï¼š0

ã€ç°åœ¨è¯·åˆ¤æ–­ã€‘
å¥å­1ï¼š{text1}
å¥å­2ï¼š{text2}

è¯·å…ˆç®€è¦åˆ†æä¸¤å¥è¯çš„æ ¸å¿ƒæ„å›¾ï¼Œç„¶åç»™å‡ºç­”æ¡ˆã€‚
ç­”æ¡ˆæ ¼å¼ï¼šåªè¾“å‡ºæ•°å­— 1 æˆ– 0ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""


def judge_similarity(text1, text2, config, show_detail=False):
    """è°ƒç”¨ API åˆ¤æ–­ä¸¤ä¸ªæ–‡æœ¬æ˜¯å¦è¯­ä¹‰ç›¸ä¼¼"""
    client = get_client(config["platform"])
    platform = PLATFORMS[config["platform"]]
    prompt = PROMPT_TEMPLATE.format(text1=text1, text2=text2)

    # æ ¹æ®å¹³å°ç±»å‹æ„é€ è¯·æ±‚å‚æ•°
    kwargs = {
        "model": config["model_id"],
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": config["max_tokens"],
    }

    # æ·»åŠ é»˜è®¤å‚æ•°
    default_params = {
        "temperature": 0.1,
    }

    # å¦‚æœæ¨¡å‹é…ç½®ä¸­æœ‰è‡ªå®šä¹‰å‚æ•°ï¼Œä½¿ç”¨è‡ªå®šä¹‰å‚æ•°è¦†ç›–é»˜è®¤å€¼
    if "params" in config:
        default_params.update(config["params"])

    # å°†å‚æ•°æ·»åŠ åˆ° kwargs
    kwargs.update(default_params)

    if platform["type"] == "openai":
        kwargs["stream"] = False
        if config.get("extra_body"):
            kwargs["extra_body"] = config["extra_body"]
    elif platform["type"] == "zhipu":
        if config.get("thinking"):
            kwargs["thinking"] = {"type": "enabled"}
        else:
            kwargs["thinking"] = {"type": "disabled"}
    elif platform["type"] == "zai":
        if config.get("thinking"):
            kwargs["thinking"] = {"type": "enabled"}
        else:
            kwargs["thinking"] = {"type": "disabled"}

    response = client.chat.completions.create(**kwargs)

    msg = response.choices[0].message
    content = (msg.content or "").strip()
    reasoning = getattr(msg, 'reasoning_content', None) or ""

    if content:
        raw_output = content
        source = "content"
    else:
        raw_output = reasoning.strip()
        source = "reasoning"

    if show_detail:
        print(f"\n{'='*60}")
        print(f"å¥å­1: {text1}")
        print(f"å¥å­2: {text2}")
        if reasoning and content:
            print(f"æ€è€ƒè¿‡ç¨‹ï¼ˆèŠ‚é€‰ï¼‰:\n{reasoning[:200]}...")
        print(f"æœ€ç»ˆè¾“å‡º [{source}]:\n{raw_output}")
        print(f"{'='*60}\n")

    # æå–æœ€ç»ˆç­”æ¡ˆ
    result = "0"

    if source == "content":
        matches = re.findall(r'(?<!\d)[01](?!\d)', raw_output)
        if matches:
            result = matches[-1]
        else:
            if 'ä¸ç›¸ä¼¼' in raw_output or 'ä¸ä¸€è‡´' in raw_output or 'ä¸åŒ' in raw_output:
                result = "0"
            elif 'ç›¸ä¼¼' in raw_output or 'ä¸€è‡´' in raw_output or 'ç›¸åŒ' in raw_output:
                result = "1"
    else:
        last_lines = raw_output.split('\n')[-3:]
        last_text = '\n'.join(last_lines)
        matches = re.findall(r'(?<!\d)[01](?!\d)', last_text)
        if matches:
            result = matches[-1]
        else:
            if 'ä¸ç›¸ä¼¼' in raw_output or 'ä¸ä¸€è‡´' in raw_output or 'ä¸åŒ' in raw_output:
                result = "0"
            elif 'ç›¸ä¼¼' in raw_output or 'ä¸€è‡´' in raw_output or 'ç›¸åŒ' in raw_output:
                result = "1"

    return result, raw_output


def main():
    parser = argparse.ArgumentParser(description="AFQMC è¯­ä¹‰ç›¸ä¼¼åº¦æ¨ç†")
    parser.add_argument("--model", type=str, default="qwen3",
                        choices=list(MODEL_CONFIGS.keys()),
                        help=f"é€‰æ‹©æ¨¡å‹: {list(MODEL_CONFIGS.keys())}")
    parser.add_argument("--workers", type=int, default=None,
                        help="å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ä½¿ç”¨æ¨¡å‹é…ç½®å€¼ï¼‰")
    args = parser.parse_args()

    config = MODEL_CONFIGS[args.model]
    max_workers = args.workers or config["max_workers"]
    model_name = args.model
    output_path = os.path.join("results", f"result_{model_name}.jsonl")

    print(f"å¹³å°: {config['platform']}")
    print(f"æ¨¡å‹: {config['model_id']} ({model_name})")
    print(f"å¹¶å‘æ•°: {max_workers}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")

    test_data = []
    with open('dataset/test.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            test_data.append(json.loads(line))

    sample_indices = set(random.sample(range(len(test_data)), min(50, len(test_data) // 100)))
    sample_indices.update({0, 1, 2})

    print(f"å…± {len(test_data)} æ¡æ•°æ®ï¼Œéšæœºæ˜¾ç¤º {len(sample_indices)} æ¡è¯¦ç»†è¾“å‡º\n")

    results = ["0"] * len(test_data)
    completed = [0]
    errors = [0]
    lock = threading.Lock()
    pbar = tqdm(total=len(test_data), desc="æ¨ç†è¿›åº¦", unit="æ¡",
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]")

    def save_results():
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            for r in results:
                f.write(json.dumps({"response": r}, ensure_ascii=False) + '\n')

    def process_item(idx, item):
        text1 = item['text1']
        text2 = item['text2']
        show_detail = idx in sample_indices

        try:
            result, _ = judge_similarity(text1, text2, config, show_detail)
            results[idx] = result
            with lock:
                completed[0] += 1
                pbar.update(1)
                if show_detail:
                    tqdm.write(f"[{completed[0]}/{len(test_data)}] #{idx+1} ç»“æœ: {result}")
                if completed[0] % 500 == 0:
                    save_results()
                    tqdm.write(f"ğŸ’¾ å·²è‡ªåŠ¨å­˜ç›˜ ({completed[0]} æ¡)")

        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "too many" in error_msg.lower():
                for retry in range(3):
                    wait = (retry + 1) * 5
                    with lock:
                        tqdm.write(f"â³ #{idx+1} é™æµï¼Œ{wait}ç§’åç¬¬{retry+1}æ¬¡é‡è¯•...")
                    time.sleep(wait)
                    try:
                        result, _ = judge_similarity(text1, text2, config, show_detail)
                        results[idx] = result
                        with lock:
                            completed[0] += 1
                            pbar.update(1)
                        return
                    except Exception:
                        continue

            with lock:
                completed[0] += 1
                errors[0] += 1
                pbar.update(1)
                tqdm.write(f"\nâŒ ç¬¬ {idx+1} æ¡å‡ºé”™: {e}")
                tqdm.write(f"   å¥å­1: {text1}")
                tqdm.write(f"   å¥å­2: {text2}\n")
            results[idx] = "0"

    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_item, i, item) for i, item in enumerate(test_data)]
            for future in as_completed(futures):
                future.result()
    except KeyboardInterrupt:
        print(f"\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¿å­˜å·²å®Œæˆçš„ {completed[0]} æ¡ç»“æœ...")

    pbar.close()
    save_results()
    print(f"\næ¨ç†å®Œæˆï¼å·²ä¿å­˜ {completed[0]}/{len(test_data)} æ¡ç»“æœåˆ° {output_path}")
    if errors[0] > 0:
        print(f"å…¶ä¸­ {errors[0]} æ¡å‡ºé”™ï¼Œé»˜è®¤æ ‡è®°ä¸º 0")


if __name__ == "__main__":
    main()
