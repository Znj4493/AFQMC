# 阶段三：模型优化与进阶技巧 - 总结报告

**完成时间**：2026年2月

---

## 1. 阶段概述

**完成的工作**：
- ✅ FGM对抗训练（+0.96%）
- ⚠️ Focal Loss损失函数（无效果）
- ✅ 类别权重优化（有效）
- ❌ EDA数据增强（负作用-0.41%）

**最终成绩**：
- F1-Macro: **71.37%**（从70.41%提升0.96%）
- Class 1召回率: 66%（从58%提升8%）

**核心收获**：
- 掌握了对抗训练的实现
- 理解了任务特性对优化方法的约束
- 学会了判断何时停止优化

---

## 2. 技术原理速览

### 2.1 对抗训练（FGM）✅ 有效（+0.96%）

**核心原理**：在embedding层添加对抗扰动，强迫模型学习更鲁棒的表示。

**训练流程**：
1. 正常训练，计算梯度
2. 在梯度方向添加小扰动（epsilon=1.0）
3. 用扰动后的样本再训练一次
4. 恢复原始参数，更新模型

**为什么有效**：AFQMC中有很多相似表述但语义不同的样本（如"花呗还款"vs"花呗还贷"），FGM让模型对这些微小变化更敏感。

---

### 2.2 Focal Loss ⚠️ 无效

**核心原理**：降低"简单样本"（模型预测很准确的）的权重，让模型更关注"困难样本"。

**公式**：`FL = -α * (1-pt)^γ * log(pt)`
- pt是预测概率，越高说明样本越简单
- (1-pt)^γ会让简单样本权重变小
- α用于平衡正负样本

**为什么没效果**：
- Focal Loss适合极度不平衡场景（如1:1000），我们的数据只有2.23:1
- 类别权重已经解决了不平衡问题，Focal Loss的作用重复了
- AFQMC的困难样本分布不够集中

---

### 2.3 类别权重 ✅ 有效

**核心原理**：给少数类样本更大的损失权重，让模型训练时更重视少数类。

**权重计算**：`weight[i] = 总样本数 / (类别数 × 该类样本数)`
- Label 0: 19,900样本 → 权重 0.72
- Label 1: 8,900样本 → 权重 1.62

**实验对比**：
- [0.72, 1.62]（2.25:1）：71.37% ✅ 最优
- [0.5, 2.5]（5:1）：70.96% ❌ 过度惩罚
- [1.0, 1.0]（1:1）：~69% ❌ 不平衡

**经验**：权重要接近数据分布比例，过度调整会导致模型失衡。

---

### 2.4 数据增强（EDA）❌ 负作用（-0.41%）

**四种操作**：
- 同义词替换（SR）：随机替换n个词
- 随机插入（RI）：随机位置插入同义词
- 随机交换（RS）：交换两个词的位置
- 随机删除（RD）：按概率删除词

**为什么失败**（⭐核心教训）：

**根本原因**：AFQMC是句子对匹配任务，不是单句分类！

举例说明：
```
单句分类（情感分析）：
输入："这部电影很好看"
标签：正面
增强："这部影片很好看" ✅
标签：正面（语义一致，没问题）

句子对匹配（AFQMC）：
输入：("花呗如何还款", "花呗怎么还钱")
标签：相似（label=1）
增强：("花呗如何还贷", "花呗怎么还钱") ❌
标签：相似（label=1）
问题：相似度已经变了，但标签还是1！
```

**三个致命问题**：
1. 只替换sentence1，改变了与sentence2的相似度
2. 但label保持不变 → 引入标注噪声
3. 同义词词典太小（20+词），覆盖率低

**正确做法**（未实现）：
- 回译：中文→英文→中文（保持语义）
- 同步增强：两个句子做相同操作
- 用BERT预测：比简单同义词准确

---

## 3. 经验总结

**有效的优化**：
- FGM对抗训练（+0.96%，几乎适用所有NLP任务）
- 适度类别权重（权重比接近数据分布）

**无效/有害的优化**：
- Focal Loss：类别不够极端不平衡（2.23:1）
- 激进权重：[0.5, 2.5]偏离数据太远
- 简单数据增强：破坏句子对关系

**核心启示**：
1. **任务特性决定方法选择**：句子对匹配≠单句分类
2. **不是所有热门方法都适用**：要分析数据特点
3. **知道何时停止优化**：MacBERT已到瓶颈（71%），继续优化边际收益低，应该尝试更强的LLM

---

## 4. 面试高频问题（通俗版）

### 4.1 对抗训练（3个问题）

**Q1: 什么是FGM对抗训练？**

A: 简单说就是"给模型出难题"。训练时故意在输入上加点小扰动（比如把embedding稍微改一改），让模型对这些变化也能预测准确。就像学生做题，除了做原题，还要做变式题，这样才能真正理解知识点。本项目中让F1提升了近1个点。

**Q2: 为什么对抗训练有用？**

A: 两个原因：一是提高鲁棒性，让模型不会因为输入稍微变化就预测错误；二是防止过拟合，相当于增加了训练数据的多样性。对于AFQMC这种语义匹配任务，经常会遇到意思差不多但表述不同的句子，FGM就能帮模型更好地理解这些细微差异。

**Q3: FGM的epsilon参数是干什么的？**

A: epsilon控制扰动的"力度"。太小了没效果，太大了会干扰正常学习。就像炒菜放盐，少了没味道，多了吃不下。一般用1.0就可以了，这是个经验值，在大多数任务上效果都不错。

---

### 4.2 损失函数（3个问题）

**Q1: Focal Loss是干什么的？**

A: Focal Loss的想法是"让模型把精力放在难题上"。那些模型已经能预测得很准的样本（简单样本），就降低它们的权重；那些模型还搞不定的样本（困难样本），就加大权重。就像老师讲课，重点讲学生不会的内容，不会一直重复学生都懂的知识。

**Q2: Focal Loss的两个参数alpha和gamma是什么意思？**

A: alpha管"数量差异"，比如正样本多负样本少，用alpha来平衡；gamma管"难易差异"，gamma越大，简单样本的权重降得越多。我们项目用的alpha=0.7（给少数类更多关注）和gamma=2.0（这是论文推荐值）。

**Q3: 为什么Focal Loss在你项目里没效果？**

A: 因为我们的数据不符合Focal Loss的适用条件。Focal Loss是为目标检测设计的，那种任务的正负样本比例可能是1:1000，极度不平衡。我们AFQMC只是2.23:1，而且类别权重已经解决了不平衡问题，Focal Loss就显得多余了。这说明不能盲目用热门方法，要看数据特点。

---

### 4.3 类别不平衡（2个问题）

**Q1: 处理类别不平衡有哪些方法？**

A: 三大类：数据层面（多生成点少数类样本，或减少多数类样本）、算法层面（给少数类更大的损失权重，或用Focal Loss）、评估层面（用F1而不是准确率来评估）。我们用的是类别权重，因为它简单有效，不改变数据就能解决问题。

**Q2: 类别权重怎么设置？如何判断设置得对不对？**

A: 常用公式是"总样本数 ÷ (类别数 × 该类样本数)"，这样少数类自然会得到更大权重。判断是否合理看三点：验证集F1有没有提升、少数类召回率有没有改善、多数类准确率有没有保持。我们试了[0.72,1.62]最好，[0.5,2.5]太激进反而降低了性能。

---

### 4.4 数据增强（4个问题）⭐ 重点

**Q1: EDA包括哪4种技术？**

A: 同义词替换（把词换成意思相近的词）、随机插入（随机位置加个同义词）、随机交换（把两个词的位置换一下）、随机删除（随机删掉一些词）。这4种操作在很多文本分类任务上都挺好用的。

**Q2: 为什么数据增强在AFQMC上失败了？**

A: 关键原因是任务类型不对。AFQMC是判断两个句子是否相似，不是单句分类。举个例子：如果我把"花呗如何还款"改成"花呗如何还贷"，它和"花呗怎么还钱"的相似度就变了，但我们的标签还是"相似"，这就引入了错误信息。就像你把题目改了但答案没变，学生就会被误导。

**Q3: 句子对匹配和单句分类有什么区别？**

A: 单句分类看的是这个句子本身是什么意思（比如这句话是正面还是负面），只要不改变句子的意思，怎么增强都行。句子对匹配看的是两个句子之间的关系（相似还是不相似），增强的时候必须保持这个关系不变。这是本质不同，决定了能用什么方法。

**Q4: 如果要给AFQMC做数据增强，应该怎么做？**

A: 三个方向：一是回译（中文翻译成英文再翻译回来，意思不变但表述变了）；二是同步增强（两个句子做相同的操作，保持相似度）；三是用BERT预测（比简单同义词替换更准确）。核心原则就是不能破坏两个句子的相似度关系。

---

### 4.5 优化策略（2个问题）

**Q1: 怎么判断一个优化方法适不适合当前任务？**

A: 三步：先看任务类型（分类、匹配还是生成），再看方法的适用条件（比如Focal Loss要求极度不平衡），最后小范围试一试（训练一个epoch看效果）。千万别看到别人用了效果好就直接抄，要结合自己的数据特点来选。

**Q2: 什么时候应该停止优化，换个思路？**

A: 三个信号：连续试了2-3种方法都没效果、验证集不涨了但训练集还没过拟合（说明模型能力不够）、花的时间超过预期收益。我们MacBERT到71%就卡住了，继续优化投入产出比太低，不如直接上LLM，预期能到85-90%。

---

## 5. 性能演进与实验对比

### 实验结果汇总

| 实验 | 配置 | F1-Macro | Class 1召回 | 变化 |
|------|------|----------|------------|------|
| 阶段二 Baseline | MacBERT + AMP | 70.41% | 58% | - |
| + FGM | epsilon=1.0 | **71.37%** | 66% | +0.96% ✅ |
| + Focal Loss | alpha=0.7, gamma=2.0 | 71.37% | 66% | 0% |
| + 激进权重 | [0.5, 2.5] | 70.96% | 63% | -0.41% ❌ |
| + 数据增强 | EDA minority | 70.96% | 60% | -0.41% ❌ |

### 完整演进路径

```
阶段二 Baseline
├─ 70.41% F1-Macro
├─ AMP + 梯度累积
└─ 类别权重 [0.72, 1.62]

       ↓ +0.96% (FGM)

71.37% ✅ 最优配置
├─ FGM对抗训练（epsilon=1.0）
├─ CE Loss + 权重[0.72, 1.62]
└─ Class 1召回率 66%

       ↓ 其他优化无效或负向

Focal Loss → 71.37% (无变化)
激进权重 → 70.96% (-0.41%)
数据增强 → 70.96% (-0.41%)
```

### 关键结论

- **最优配置**：FGM + CE Loss + 权重[0.72, 1.62]
- **唯一有效提升**：FGM对抗训练（+0.96%）
- **MacBERT已达瓶颈**：继续优化边际收益低
- **下一步**：阶段四LLM微调（目标85-90%）

---

## 6. 阶段反思

**本阶段收获**：
- 技术：掌握FGM对抗训练、类别权重调优
- 思维：学会判断方法是否适用当前任务
- 经验：认识到任务特性的重要性（句子对匹配≠单句分类）

**未完成的优化**（为什么不做）：
- 学习率策略、PGM对抗训练、K-fold交叉验证
- 原因：边际收益<1%，投入产出比低，LLM提升空间更大（+15%）

**下一步计划**：
- 进入阶段四：Qwen-1.8B + LoRA微调
- 预期性能：85-90% F1-Macro
- 核心亮点：掌握2026求职最热门技术

---

**总结完成时间**：2026年2月6日
**准备进入**：阶段四 - 大语言模型（LLM）微调
